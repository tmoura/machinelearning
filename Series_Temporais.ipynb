{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Series-Temporais.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPiUwXMAKaVG3ffmXIC6VrO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmoura/machinelearning/blob/master/Series_Temporais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNFpCJsks6Hh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "path = 'https://raw.githubusercontent.com/EraylsonGaldino/dataset_time_series/master/goldman.txt'\n",
        "dados = pd.read_csv(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiNdfCWXtAj3"
      },
      "source": [
        "min = 0\n",
        "max = 1\n",
        "scaler = MinMaxScaler(feature_range=(min, max)).fit(dados)\n",
        "serie_normalizada = scaler.transform(dados.values.reshape(1, -1))\n",
        "\n",
        "dados['Normalizado'] = serie_normalizada[0]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2UH3HZ4tCx2"
      },
      "source": [
        "def create_sliding_windows(series, window_size):\n",
        "   \n",
        "    list_of_sliding_windows = []\n",
        "    list_size_to_iterate = len(series) - window_size \n",
        "    for i in range(0, list_size_to_iterate):\n",
        "        window = series[i: i + window_size + 1]\n",
        "        list_of_sliding_windows.append(window)\n",
        "\n",
        "    return np.array(list_of_sliding_windows).reshape(len(list_of_sliding_windows), window_size+1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVGl3Y4otS6_"
      },
      "source": [
        "## **DÚVIDA NA PRÓXIMA CÉLULA**\n",
        "\n",
        "Perguntas:\n",
        "\n",
        "1) No código que você me passou, você divide a base de treinamento e teste por intervalo de datas, mas no paper você simplesmente separou os 80% primeiros padrões para treinamento e os últimos 20% para teste.\n",
        "\n",
        "Aqui, depois da normalização, eu vou criar as janelas com os lags de 20 para depois separar em treinamento e teste, confere?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acueedtYypun"
      },
      "source": [
        "windows_train = create_sliding_windows(dados['Normalizado'], 20)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3_G7UQ1zdrr"
      },
      "source": [
        "perc_val = 0.2\n",
        "tam_val = np.fix(len(windows_train) * perc_val).astype(int)\n",
        "\n",
        "X_train, y_train = windows_train[0:-tam_val, 0:-1], windows_train[0:-tam_val, -1]\n",
        "X_val, y_val = windows_train[-tam_val:, 0:-1], windows_train[-tam_val:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA4OQQEg0Hin"
      },
      "source": [
        "pontos_anteriores_test = train_data.values[-20:]\n",
        "test = np.hstack([pontos_anteriores_test, test_data.values])\n",
        "\n",
        "windows_test = create_sliding_windows(test, 20)\n",
        "X_test, y_test = windows_test[:, 0:-1], windows_test[:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCD8EhcZtKEi"
      },
      "source": [
        "def select_lag_acf(serie, max_lag):\n",
        "    from statsmodels.tsa.stattools import acf\n",
        "    x = serie[0: max_lag+1]\n",
        "    \n",
        "    acf_x, confint = acf(serie, nlags=max_lag, alpha=.05, fft=False,\n",
        "                             unbiased=False)\n",
        "    \n",
        "    \n",
        "    limiar_superior = confint[:, 1] - acf_x\n",
        "    limiar_inferior = confint[:, 0] - acf_x\n",
        "\n",
        "    lags_selecionados = []\n",
        "    \n",
        "    for i in range(1, max_lag+1):\n",
        "\n",
        "        \n",
        "        if acf_x[i] >= limiar_superior[i] or acf_x[i] <= limiar_inferior[i]:\n",
        "            lags_selecionados.append(i-1)  #-1 por conta que o lag 1 em python é o 0\n",
        "    \n",
        "    #caso nenhum lag seja selecionado, essa atividade de seleção para o gridsearch encontrar a melhor combinação de lags\n",
        "    if len(lags_selecionados)==0:\n",
        "\n",
        "\n",
        "        print('NENHUM LAG POR ACF')\n",
        "        lags_selecionados = [i for i in range(max_lag)]\n",
        "\n",
        "    print('LAGS', lags_selecionados)\n",
        "\n",
        "    #inverte o valor dos lags para usar na lista de dados\n",
        "    lags_selecionados = [max_lag - (i+1) for i in lags_selecionados]\n",
        "\n",
        "    return lags_selecionados"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDpClhZhuUg6"
      },
      "source": [
        "## **DÚVIDA NA PRÓXIMA CÉLULA**\n",
        "\n",
        "Perguntas:\n",
        "\n",
        "1) Fiz testes com a base goldman, star e msft e praticamente os lags selecionados foram quase os mesmos, com a remoção de um ou outro lag, praticamente as 3 bases usaram todos os lags. É isso mesmo?? O código da função acima (\"select_lag_acf\") tá correto??\n",
        "\n",
        "Resolvendo isso, eu transformo as bases, já as deixo prontas em python, salvo em CSV e só rodo meu código no MATLAB e pronto!\n",
        "\n",
        "Tive ideia de outro artigo para a gente trabalhar!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph9FoHcDtQ49"
      },
      "source": [
        "lags_sel = select_lag_acf(dados['Normalizado'], 20)\n",
        "\n",
        "print(lags_sel)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}