{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Series-Temporais.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOKbUJsVc/SsAWu/dlHYdBZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmoura/machinelearning/blob/master/Series_Temporais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNFpCJsks6Hh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "path = 'https://raw.githubusercontent.com/EraylsonGaldino/dataset_time_series/master/goldman.txt'\n",
        "dados = pd.read_csv(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiNdfCWXtAj3"
      },
      "source": [
        "min = 0\n",
        "max = 1\n",
        "scaler = MinMaxScaler(feature_range=(min, max)).fit(dados)\n",
        "serie_normalizada = scaler.transform(dados.values.reshape(1, -1))\n",
        "\n",
        "dados['Normalizado'] = serie_normalizada[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2UH3HZ4tCx2"
      },
      "source": [
        "def create_sliding_windows(series, window_size):\n",
        "   \n",
        "    list_of_sliding_windows = []\n",
        "    list_size_to_iterate = len(series) - window_size \n",
        "    for i in range(0, list_size_to_iterate):\n",
        "        window = series[i: i + window_size + 1]\n",
        "        list_of_sliding_windows.append(window)\n",
        "\n",
        "    return np.array(list_of_sliding_windows).reshape(len(list_of_sliding_windows), window_size+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVGl3Y4otS6_"
      },
      "source": [
        "## **DÚVIDA NA PRÓXIMA CÉLULA**\n",
        "\n",
        "Perguntas:\n",
        "\n",
        "1) No código que você me passou, você divide a base de treinamento e teste por intervalo de datas, mas no paper você simplesmente separou os 80% primeiros padrões para treinamento e os últimos 20% parra teste, né isso? Em todas as bases testadas??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqjRNpLQtFcI"
      },
      "source": [
        "qtd_lag = 20\n",
        "\n",
        "#treinamento e teste\n",
        "#train_data, test_data = dados['Normalizado'].loc['2000':'2011'], dados['Normalizado'].loc['2012':]\n",
        "#windows_train = create_sliding_windows(train_data.values, 20) ????????"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCD8EhcZtKEi"
      },
      "source": [
        "def select_lag_acf(serie, max_lag):\n",
        "    from statsmodels.tsa.stattools import acf\n",
        "    x = serie[0: max_lag+1]\n",
        "    \n",
        "    acf_x, confint = acf(serie, nlags=max_lag, alpha=.05, fft=False,\n",
        "                             unbiased=False)\n",
        "    \n",
        "    \n",
        "    limiar_superior = confint[:, 1] - acf_x\n",
        "    limiar_inferior = confint[:, 0] - acf_x\n",
        "\n",
        "    lags_selecionados = []\n",
        "    \n",
        "    for i in range(1, max_lag+1):\n",
        "\n",
        "        \n",
        "        if acf_x[i] >= limiar_superior[i] or acf_x[i] <= limiar_inferior[i]:\n",
        "            lags_selecionados.append(i-1)  #-1 por conta que o lag 1 em python é o 0\n",
        "    \n",
        "    #caso nenhum lag seja selecionado, essa atividade de seleção para o gridsearch encontrar a melhor combinação de lags\n",
        "    if len(lags_selecionados)==0:\n",
        "\n",
        "\n",
        "        print('NENHUM LAG POR ACF')\n",
        "        lags_selecionados = [i for i in range(max_lag)]\n",
        "\n",
        "    print('LAGS', lags_selecionados)\n",
        "\n",
        "    #inverte o valor dos lags para usar na lista de dados\n",
        "    lags_selecionados = [max_lag - (i+1) for i in lags_selecionados]\n",
        "\n",
        "    return lags_selecionados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDpClhZhuUg6"
      },
      "source": [
        "## **DÚVIDA NA PRÓXIMA CÉLULA**\n",
        "\n",
        "Perguntas:\n",
        "\n",
        "1) Fiz testes com a base goldman, star e msft e praticamente os lags selecionados foram quase os mesmos, com a remoção de um ou outro lag, praticamente as 3 bases usaram todos os lags. É isso mesmo?? O código da função acima (\"select_lag_acf\") tá correto??\n",
        "\n",
        "Resolvendo isso, eu trannsformo as bases, já as deixo prontas em python, salvo em CSV e só rodo meu código no MATLAB e pronto!\n",
        "\n",
        "Tive ideia de outro artigo para a gente trabalhar!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "Ph9FoHcDtQ49",
        "outputId": "7c24df60-6b62-4dc6-9578-5f072b68d48b"
      },
      "source": [
        "lags_sel = select_lag_acf(dados['Normalizado'], 20)\n",
        "\n",
        "print(lags_sel)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3fbf416313a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlags_sel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_lag_acf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdados\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Normalizado'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlags_sel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'select_lag_acf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEiGuWYEu9i6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}